#!/usr/bin/env python3
"""
æµ‹è¯•æ–°çš„fact_checkerå…¼å®¹æ€§
"""
import sys
from pathlib import Path
project_path = Path(__file__).parent
sys.path.insert(0, str(project_path))

from utils import calculate_average_score, format_feedback_summary

def test_fact_checker_compatibility():
    """æµ‹è¯•fact_checkerä¸åŒè¾“å‡ºæ ¼å¼çš„å…¼å®¹æ€§"""

    print("ğŸ§ª æµ‹è¯•fact_checkerè¾“å‡ºæ ¼å¼å…¼å®¹æ€§...")

    # 1. æµ‹è¯•æ—§æ ¼å¼
    old_format = {
        "fact_checker": {
            "score": 85,
            "is_logical": True,
            "is_based_on_original": True,
            "overall_comment": "æ•…äº‹é€»è¾‘åŸºæœ¬æ¸…æ™°",
            "issues": [
                {
                    "location": "ç¬¬3æ®µ",
                    "problem": "äººç‰©åŠ¨æœºä¸å¤Ÿæ¸…æ™°",
                    "severity": "ä¸­ç­‰",
                    "suggestion": "è¡¥å……è§’è‰²èƒŒæ™¯è¯´æ˜"
                }
            ],
            "suggestions": [
                "å¢åŠ è§’è‰²èƒŒæ™¯è¯´æ˜",
                "æ¸…æ™°åŒ–åŠ¨æœº"
            ]
        }
    }

    old_score = calculate_average_score(old_format)
    old_summary = format_feedback_summary(old_format)
    print(f"æ—§æ ¼å¼æµ‹è¯•: è¯„åˆ†={old_score}, æ‘˜è¦='{old_summary}'")

    # 2. æµ‹è¯•æ–°æ ¼å¼ - å•æ®µè¯„å®¡
    new_format_single = {
        "fact_checker": {
            "original_excerpt": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ®µè½...",
            "applied_strategies": [
                {
                    "strategy_type": "A",
                    "specific_technique": "A_æ¬²æœ›-éšœç¢æ¨¡å‹",
                    "effectiveness": "high",
                    "context_fit": "æ”¯æ’‘å½“å‰æƒ…èŠ‚"
                }
            ],
            "logic_gaps": [
                {
                    "gap_type": "åŠ¨æœºç¼ºå¤±",
                    "missing_strategy": "A_æ¬²æœ›-éšœç¢æ¨¡å‹",
                    "symptom": "è¯»è€…æ— æ³•ç†è§£ä¸»è§’ä¸ºä½•å†’é™©",
                    "location": "ç¬¬3æ®µ",
                    "suggestion": "æ·»åŠ åŠ¨æœºè¯´æ˜"
                }
            ],
            "strengths": [
                "B_è§„åˆ™é”šå®šæ¸…æ™°"
            ],
            "genre_alignment": ["ç„å¹»"]
        }
    }

    new_score = calculate_average_score(new_format_single)
    new_summary = format_feedback_summary(new_format_single)
    print(f"æ–°æ ¼å¼(å•æ®µ)æµ‹è¯•: è¯„åˆ†={new_score}, æ‘˜è¦='{new_summary}'")

    # 3. æµ‹è¯•æ–°æ ¼å¼ - ä¸–ç•Œè§‚è®¾å®šè¯„å®¡
    new_format_setting = {
        "fact_checker": {
            "setting_summary": "ä¸€ä¸ªå¥‡å¹»ä¸–ç•Œè§‚...",
            "coherence_score": "high",
            "anchored_rules": ["é­”æ³•æ¶ˆè€—å¯¿å‘½", "çš‡æ—è¡€è„‰å¯é©­é¾™"],
            "unanchored_risks": [
                {
                    "rule": "é¾™å¯ä»¥ç©¿è¶Šæ—¶ç©º",
                    "risk": "æœªè¯´æ˜é™åˆ¶æ¡ä»¶",
                    "fix_strategy": "B_è§„åˆ™é”šå®š"
                }
            ],
            "character_motivation_support": "A_æ¬²æœ›-éšœç¢æ¨¡å‹å¯æ”¯æ’‘å¤šè§’è‰²",
            "recommended_additions": [
                "æ·»åŠ  B_å†å²å±‚ç§¯"
            ]
        }
    }

    setting_score = calculate_average_score(new_format_setting)
    setting_summary = format_feedback_summary(new_format_setting)
    print(f"æ–°æ ¼å¼(è®¾å®š)æµ‹è¯•: è¯„åˆ†={setting_score}, æ‘˜è¦='{setting_summary}'")

    # æµ‹è¯•å¤šä»£ç†æ··åˆ
    mixed_feedback = {**old_format, **new_format_single, **new_format_setting}
    mixed_score = calculate_average_score(mixed_feedback)
    mixed_summary = format_feedback_summary(mixed_feedback)
    print(f"æ··åˆæ ¼å¼æµ‹è¯•: è¯„åˆ†={mixed_score:.1f}")
    print(f"æ‘˜è¦: {mixed_summary}")

    print("âœ… æµ‹è¯•å®Œæˆï¼æ–°æ—§æ ¼å¼å…¼å®¹æ€§æ­£å¸¸")


if __name__ == "__main__":
    test_fact_checker_compatibility()