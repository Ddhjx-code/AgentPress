#!/usr/bin/env python3
"""
å®‰å¾’ç”Ÿç«¥è¯å…¨é¢åˆ†æè„šæœ¬ - ä½¿ç”¨ä¼˜åŒ–åçš„åˆ†æ®µåˆ†æç³»ç»Ÿ
"""
import asyncio
import sys
from pathlib import Path
import os
from dotenv import load_dotenv
import time

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from core.workflow_service import WorkflowService
from knowledge.novel_knowledge_extender import NovelKnowledgeExtender

load_dotenv()  # åŠ è½½ç¯å¢ƒå˜é‡


async def analyze_anded_sheng():
    """ä½¿ç”¨æ–°ä¼˜åŒ–ç³»ç»Ÿåˆ†æå®‰å¾’ç”Ÿç«¥è¯"""
    print("ğŸ“š å¼€å§‹ä½¿ç”¨ä¼˜åŒ–ç³»ç»Ÿåˆ†æå®‰å¾’ç”Ÿç«¥è¯")
    print("="*60)

    workflow_service = WorkflowService()

    # è·å–APIé…ç½®
    api_key = os.getenv("QWEN_API_KEY", "")
    base_url = os.getenv("BASE_URL", "https://apis.iflow.cn/v1")
    model_name = os.getenv("MODEL_NAME", "qwen3-max")

    if not api_key:
        print("âš ï¸  æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ QWEN_API_KEY è®¾ç½®")
        return

    print("âœ… APIå¯†é’¥å·²åŠ è½½")

    # åˆå§‹åŒ–æ¨¡å‹
    start_init_time = time.time()
    try:
        await workflow_service.initialize_models(
            api_key=api_key,
            base_url=base_url,
            model_name=model_name
        )
        print(f"âœ… å·¥ä½œæµæœåŠ¡åˆå§‹åŒ–å®Œæˆ (è€—æ—¶: {time.time() - start_init_time:.1f}ç§’)")
    except Exception as e:
        print(f"âŒ å·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # åˆ›å»ºæ‰©å±•ç®¡ç†å™¨å¹¶ä½¿ç”¨ä¼˜åŒ–åˆ†æ
    extender = NovelKnowledgeExtender(workflow_service)

    # åˆ†æå•ä¸ªPDFæ–‡ä»¶
    start_process_time = time.time()
    result = await extender.process_pdf_and_import("å®‰å¾’ç”Ÿç«¥è¯é€‰.pdf")

    total_time = time.time() - start_process_time
    print(f"â±ï¸  å®‰å¾’ç”Ÿç«¥è¯åˆ†æå®Œæˆ (æ€»è€—æ—¶: {total_time:.1f}ç§’)")
    print()

    # æ˜¾ç¤ºç»“æœç»Ÿè®¡
    print("ğŸ“Š å¤„ç†ç»“æœ:")
    print(f"   åŸå§‹PDFæ–‡ä»¶: {result['pdf_file']}")
    print(f"   åˆ†ææ®µè½æ•°: {result['total_segments_analyzed']}")
    print(f"   çŸ¥è¯†æ¡ç›®åˆ›å»ºæ•°: {result['knowledge_entries_created']}")
    print(f"   æˆåŠŸå¯¼å…¥æ•°: {result['successful_imports']}")
    print(f"   å¤±è´¥æ•°é‡: {result['failed_imports']}")
    print()

    # æå–å®Œæ•´çŸ¥è¯†åº“ä¿¡æ¯
    stats = await extender.get_novel_analysis_stats()
    print("ğŸ¯ çŸ¥è¯†åº“å½“å‰ç»Ÿè®¡:")
    print(f"   æ€»çŸ¥è¯†æ¡ç›®æ•°: {stats['total_knowledge_entries']}")
    print(f"   å°è¯´åˆ†æç›¸å…³æ¡ç›®: {stats['novel_analysis_entries']}")
    print(f"   æŒ‰ç±»å‹åˆ†å¸ƒ: {stats['breakdown_by_type']}")

    # æ˜¾ç¤ºéƒ¨åˆ†æ–°åˆ›å»ºçš„çŸ¥è¯†æ¡ç›®
    all_entries = await extender.km.get_all_entries()
    created_entries = [e for e in all_entries if 'å®‰å¾’ç”Ÿç«¥è¯é€‰' in e.source]

    print()
    print(f"ğŸ“ æ–°å¢åˆ†ææ¡ç›®ç¤ºä¾‹ (æ˜¾ç¤ºå‰5ä¸ª):")
    for i, entry in enumerate(created_entries[-5:]):  # æ˜¾ç¤ºæœ€æ–°åˆ›å»ºçš„5ä¸ª
        print(f"   {i+1}. ã€{entry.knowledge_type}ã€‘ {entry.title}")
        print(f"      æ ‡ç­¾: {entry.tags}")
        print(f"      å¤§å°: {len(entry.content)} å­—ç¬¦")
        print(f"      å†…å®¹é¢„è§ˆ: {entry.content[:120]}...")
        print()

    print("="*60)
    print("âœ… å®‰å¾’ç”Ÿç«¥è¯åˆ†æå®Œæˆï¼")
    print("   æ•°æ®å·²ä¿å­˜åˆ° knowledge base ä¾›åç»­åˆ›ä½œå‚è€ƒ")


def sync_main():
    """åŒæ­¥å…¥å£ç‚¹"""
    import asyncio

    if sys.platform.startswith("win"):
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

    asyncio.run(analyze_anded_sheng())


if __name__ == "__main__":
    sync_main()