"""
ç ”ç©¶è§„åˆ’é˜¶æ®µç®¡ç†å™¨
é‡æ„åçš„ç ”ç©¶é˜¶æ®µï¼Œä¸“é—¨è´Ÿè´£åˆ›æ„æ¦‚å¿µçš„åˆ†æå’Œè§„åˆ’
"""
from typing import Dict, Any
from core.agent_handlers_map import AgentHandlersMap
from src.documentation_manager import DocumentationManager
from core.conversation_manager import ConversationManager
from src.agents.mythologist_agent import MythologistAgentHandler
from config import GROUPCHAT_CONFIGS, CREATION_CONFIG
from utils import extract_content
import re


class ResearchPhase:
    """
    é‡æ„åçš„ç ”ç©¶è§„åˆ’é˜¶æ®µ
    ä½¿ç”¨ä¸“ä¸šagentå¤„ç†å™¨æ‰§è¡Œç ”ç©¶ä»»åŠ¡
    """

    def __init__(self, agent_handlers_map: AgentHandlersMap, documentation_manager: DocumentationManager,
                 conversation_manager: ConversationManager):
        """
        åˆå§‹åŒ–ç ”ç©¶é˜¶æ®µç®¡ç†å™¨

        Args:
            agent_handlers_map: agentå¤„ç†å™¨æ˜ å°„æœåŠ¡
            documentation_manager: æ–‡æ¡£ç®¡ç†å™¨
            conversation_manager: å¯¹è¯ç®¡ç†å™¨
        """
        self.agent_handlers_map = agent_handlers_map
        self.doc_manager = documentation_manager
        self.conversation_manager = conversation_manager

    async def execute_research(self, novel_concept: str, previous_context: str = "", previous_documentation: Dict = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„åˆ›æ„ç ”ç©¶å’Œè§„åˆ’é˜¶æ®µ

        Args:
            novel_concept: å°è¯´åˆ›æ„æ¦‚å¿µ
            previous_context: ä¹‹å‰çš„ç»­å†™ä¸Šä¸‹æ–‡ï¼ˆç”¨äºé•¿ç¯‡å°è¯´ç»­å†™ï¼‰
            previous_documentation: ä¹‹å‰çš„æ–‡æ¡£æ•°æ®ï¼ˆç”¨äºä¿æŒä¸€è‡´æ€§ï¼‰

        Returns:
            åŒ…å«ç ”ç©¶å’Œè§„åˆ’ç»“æœçš„å­—å…¸
        """
        print("\\n" + "="*60)
        print("ğŸ” ç¬¬ä¸€é˜¶æ®µï¼šåˆ›æ„ç ”ç©¶ä¸è§„åˆ’")
        print("="*60)

        # å¦‚æœæœ‰ä¹‹å‰çš„ä¸Šä¸‹æ–‡ï¼Œé€šçŸ¥ç”¨æˆ·
        if previous_context:
            print(f"ğŸ“š æ£€æµ‹åˆ°ç»­å†™æ¨¡å¼ï¼Œå·²åŠ è½½ä¹‹å‰ç« èŠ‚å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡å‚è€ƒ")
            if previous_documentation:
                print(f"ğŸ“ å·²åŠ è½½ä¹‹å‰çš„æ•…äº‹æ–‡æ¡£ï¼Œå°†ç”¨äºä¿æŒä¸€è‡´æ€§")

        # å¤„ç†ä¸Šä¸‹æ–‡ï¼šå¦‚æœç»­å†™ï¼Œåˆå¹¶æ¦‚å¿µä¸ä¸Šä¸‹æ–‡å’Œå…¶ä»–æ–‡æ¡£ä¿¡æ¯
        full_context = novel_concept

        if previous_context:
            # ä»previous_documentationæå–ç»“æ„åŒ–ä¿¡æ¯
            documentation_summary = ""
            if previous_documentation and isinstance(previous_documentation, dict):
                documentation_summary += "## æ–‡æ¡£æ‘˜è¦ä¾›å‚è€ƒï¼š\n"

                # æ·»åŠ è§’è‰²ä¿¡æ¯
                if "characters" in previous_documentation and previous_documentation["characters"]:
                    characters = list(previous_documentation["characters"].keys())
                    if characters:
                        documentation_summary += f"è§’è‰²åˆ—è¡¨ï¼š{', '.join(characters[:10])}{'...' if len(characters) > 10 else ''}\n"

                # æ·»åŠ ä¸–ç•Œè®¾å®š
                if "world_rules" in previous_documentation and previous_documentation["world_rules"]:
                    rules = list(previous_documentation["world_rules"].keys())
                    documentation_summary += f"ä¸–ç•Œè§„åˆ™ï¼š{', '.join(rules[:10])}{'...' if len(rules) > 10 else ''}\n"

                # æ·»åŠ é‡è¦åœ°ç‚¹
                if "settings_locations" in previous_documentation and previous_documentation["settings_locations"]:
                    locations = list(previous_documentation["settings_locations"].keys())
                    documentation_summary += f"é‡è¦åœ°ç‚¹ï¼š{', '.join(locations[:10])}{'...' if len(locations) > 10 else ''}\n"

                documentation_summary += "\n"

            full_context = f"## ç»­å†™æ¨¡å¼ - å·²æœ‰ä¸Šä¸‹æ–‡:\n{previous_context}\n\n{documentation_summary}## æ–°çš„ç»­å†™è¦æ±‚:\n{novel_concept}\n\nè¯·åŸºäºå·²æœ‰å†…å®¹å’Œè®¾å®šç»§ç»­åˆ›ä½œï¼Œå¹¶ä¿æŒé£æ ¼ã€äººç‰©å’Œè®¾å®šçš„ä¸€è‡´æ€§ã€‚é‡è¦çš„æ˜¯è¦æ³¨æ„è§’è‰²å‘å±•å’Œæƒ…èŠ‚è¿è´¯æ€§ã€‚"

        # 1. æ‰§è¡Œè·¨æ–‡åŒ–ç¬¦å·ç­–ç•¥åˆ†æ (Mythologist)
        print("\\nğŸ“– å¼€å§‹è·¨æ–‡åŒ–ç¬¦å·ç­–ç•¥åˆ†æ...")
        mythologist_handler = self.agent_handlers_map.get_handler("mythologist")
        if mythologist_handler:
            mythologist_result = await mythologist_handler.process(full_context)
            symbol_analysis = mythologist_result.get("parsed_json", {})
        else:
            symbol_analysis = {}
            print("âš ï¸  Mythologistä»£ç†ä¸å¯ç”¨")

        # 2. ä½¿ç”¨Writerä»£ç†ç”Ÿæˆåˆæ­¥å¤§çº² - åŒæ—¶è€ƒè™‘å­—æ•°è¦æ±‚å’Œä¸Šä¸‹æ–‡
        writer_handler = self.agent_handlers_map.get_handler("writer")
        if writer_handler:
            print("ğŸ“‹ ç”Ÿæˆåˆæ­¥å¤§çº²...")

            # å°è¯•ä»æ¦‚å¿µä¸­æå–ç”¨æˆ·æŒ‡å®šçš„å­—æ•°è¦æ±‚
            import re
            # æŸ¥æ‰¾ç±»ä¼¼"13000å­—", "5000å­—ä»¥ä¸Š", "#å­—æ•°ï¼š15000å­—ä»¥ä¸Š"ç­‰æ¨¡å¼
            word_count_patterns = [
                r"(?i:è¦æ±‚?[:ï¼š]?\s*(\d+)[å­—è¬è¬])",  # åŒ¹é…"è¦æ±‚XXXå­—"
                r"(?i:è¦æ±‚?\s*(\d+)[,ï¼Œ]?\s*[å­—è¬è¬]\s*ä»¥ä¸Š)",  # åŒ¹é…"XXXå­—ä»¥ä¸Š"
                r"(?i:[#\n]å­—æ•°?[ï¼š:]?\s*(\d+)[,ï¼Œ]?\s*[å­—è¬è¬])",  # åŒ¹é…"#å­—æ•°XXXå­—"æˆ–"å­—æ•°ï¼šXXXå­—"
                r"(?i:[#]ç±»å‹[:ï¼š]?\s*[^\\n]*\n.*?(\d+)[,ï¼Œ]?\s*[å­—è¬è¬])",  # åŒ¹é…"ç±»å‹ï¼š...XXXå­—"
            ]

            specified_target = None
            for pattern in word_count_patterns:
                match = re.search(pattern, novel_concept)
                if match:
                    raw_number = match.group(1)
                    # å¤„ç†"è¬"å­—ç¬¦
                    if 'è¬' in raw_number or 'ä¸‡' in raw_number:
                        number = raw_number.replace('è¬', '').replace('ä¸‡', '')
                        specified_target = int(number) * 10000
                    else:
                        specified_target = int(raw_number)
                    break

            if specified_target:
                print(f"ğŸ“Š æ£€æµ‹åˆ°æ¦‚å¿µä¸­çš„ç›®æ ‡å­—æ•°è¦æ±‚: {specified_target} å­—")
            else:
                # é¢å¤–æ£€æŸ¥ "å­—ä»¥ä¸Š" æˆ–å…¶ä»–æ¨¡å¼
                more_pattern = r'(\d+)[,ï¼Œ]?\s*å­—\s*ä»¥ä¸Š'
                more_match = re.search(more_pattern, novel_concept)
                if more_match:
                    specified_target = int(more_match.group(1))
                    print(f"ğŸ“Š æ£€æµ‹åˆ°æ¦‚å¿µä¸­çš„æœ€ä½å­—æ•°è¦æ±‚: {specified_target} å­—ï¼ˆä»¥ä¸Šï¼‰")

            # åˆ›å»ºé’ˆå¯¹ç»­å†™çš„ä»»åŠ¡æè¿°
            if previous_context:
                outline_task = f"""æ‚¨æ­£åœ¨ç»­å†™ä¸€éƒ¨å°è¯´ã€‚ä»¥ä¸‹æ˜¯æœ‰ç”¨çš„å‚è€ƒä¿¡æ¯ï¼š

## ä¹‹å‰çš„åˆ›ä½œå†…å®¹ï¼ˆè¯·ä¿æŒä¸€è‡´æ€§ï¼‰ï¼š
{previous_context}

## æ–°çš„ç»­å†™è¦æ±‚ï¼š
{novel_concept}

è¯·åŸºäºå·²æœ‰å†…å®¹ç»§ç»­åˆ›ä½œï¼Œå¹¶ä¿æŒä»¥ä¸‹æ–¹é¢çš„ä¸€è‡´æ€§ï¼š
1. äººç‰©æ€§æ ¼å’Œå…³ç³»
2. ä¸–ç•Œè§‚å’Œè§„åˆ™
3. å†™ä½œé£æ ¼å’Œè¯­è°ƒ
4. æƒ…èŠ‚è¿è´¯æ€§

åŒæ—¶è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. æ ¸å¿ƒå†²çªå’Œæƒ…èŠ‚ä¸»çº¿ï¼ˆå»¶ç»­ä¹‹å‰çš„æ•…äº‹çº¿ï¼‰
2. ä¸»è¦è§’è‰²è®¾å®šï¼ˆä½¿ç”¨å·²æœ‰è§’è‰²ï¼‰
3. æœ¬éƒ¨åˆ†ç« èŠ‚ç»“æ„è§„åˆ’
4. é¢„æœŸé£æ ¼å’ŒåŸºè°ƒçš„å»¶ç»­
5. ä¸å‰é¢å†…å®¹çš„è¡”æ¥ç‚¹"""
            else:
                outline_task = f"""åŸºäºä»¥ä¸‹åˆ›æ„æ¦‚å¿µæä¾›åˆæ­¥çš„åˆ›ä½œå¤§çº²ï¼š

åˆ›æ„æ¦‚å¿µ: {novel_concept}

è¯·ç‰¹åˆ«å…³æ³¨åˆ›æ„æ¦‚å¿µä¸­æŒ‡å®šçš„ç¯‡å¹…è¦æ±‚ï¼Œå¹¶åˆ¶å®šç›¸åº”çš„åˆ›ä½œè§„åˆ’ã€‚
å¦‚æœæ¦‚å¿µä¸­æŒ‡å®šäº†ç›®æ ‡å­—æ•°ï¼Œè¯·ä¸¥æ ¼éµå¾ªè¯¥è¦æ±‚ã€‚

åˆ›ä½œå¤§çº²è¦æ±‚åŒ…å«ï¼š
1. æ ¸å¿ƒå†²çªå’Œæƒ…èŠ‚ä¸»çº¿
2. ä¸»è¦è§’è‰²è®¾å®š
3. åŸºæœ¬ç»“æ„è§„åˆ’ï¼ˆåŒ…å«é¢„è®¡çš„ç« èŠ‚åˆ’åˆ†ä»¥æ»¡è¶³ç¯‡å¹…è¦æ±‚ï¼‰
4. é¢„æœŸé£æ ¼å’ŒåŸºè°ƒ
5. ç¯‡å¹…è§„åˆ’ç­–ç•¥"""

            outline_result = await writer_handler.process(outline_task)
            outline = outline_result.get("content", "")

            # ç¡®å®šç›®æ ‡é•¿åº¦ï¼Œä¼˜å…ˆçº§ï¼šç”¨æˆ·æ¦‚å¿µ > AIåˆ†æ > é…ç½® > é»˜è®¤å€¼
            target_length = 5000  # é»˜è®¤å€¼

            # ä¼˜å…ˆä½¿ç”¨ä»ç”¨æˆ·æ¦‚å¿µä¸­è§£æçš„ç›®æ ‡å­—æ•°
            if specified_target:
                target_length = specified_target
            elif symbol_analysis and isinstance(symbol_analysis, dict):
                if "target_length" in symbol_analysis:
                    # åªæœ‰å½“AIå»ºè®®çš„é•¿åº¦ä¸åŒäºç”¨æˆ·æŒ‡å®šæ—¶æ‰æ›´æ–°
                    if not specified_target:  # å¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šï¼Œåˆ™ä½¿ç”¨AIåˆ†æçš„
                        target_length = symbol_analysis["target_length"].get("suggested", 5000)
                elif not specified_target:  # å¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šï¼Œåˆ™ä½¿ç”¨AIåˆ†æçš„
                    if symbol_analysis.get("suggested_length"):
                        target_length = symbol_analysis["suggested_length"]

            print(f"ğŸ¯ ç¡®å®šæœ€ç»ˆåˆ›ä½œå­—ç›®æ ‡: {'æ¦‚å¿µæŒ‡å®š' if specified_target else 'AIåˆ†æ' if symbol_analysis else 'é»˜è®¤é…ç½®'} -> {target_length} å­—ç¬¦")
        else:
            outline = f"åŸºäº {novel_concept} çš„ç²—ç•¥è§„åˆ’"
            print("âš ï¸  Writerä»£ç†ä¸å¯ç”¨")

        # 3. ä¿å­˜ç ”ç©¶é˜¶æ®µç»“æœåˆ°æ–‡æ¡£ç®¡ç†å™¨ - ä½¿ç”¨ç¬¦åˆDocumentationManagerç»“æ„çš„æ•°æ®
        research_doc_data = {
            "characters": {},  # ç ”ç©¶é˜¶æ®µå¯èƒ½è¿˜æ²¡æœ‰ç‰¹å®šçš„è§’è‰²
            "timeline": [{"event": "concept_analysis", "description": novel_concept, "timestamp": __import__('datetime').datetime.now().isoformat()}],
            "world_rules": {},  # åœ¨åé¢é˜¶æ®µæå–
            "plot_points": [outline] if outline else [],  # æ•…äº‹å¤§çº²ä½œä¸ºä¸€ä¸ªæƒ…èŠ‚ç‚¹
            "settings_locations": {},  # ç ”ç©¶é˜¶æ®µå¯èƒ½è¿˜æ²¡æœ‰ç‰¹å®šè®¾ç½®
            "updated_at": __import__('datetime').datetime.now().isoformat()
        }

        import json
        self.doc_manager.update_documentation(json.dumps(research_doc_data, ensure_ascii=False))

        # 4. è®°å½•AIä»£ç†è®¨è®ºä¼šè®®çºªè¦
        participants = []
        if self.agent_handlers_map.get_handler("mythologist"):
            participants.append("mythologist")
        if self.agent_handlers_map.get_handler("writer"):
            participants.append("writer")

        meeting_summary = f"å®Œæˆåˆ›æ„æ¦‚å¿µç ”ç©¶ï¼Œç”Ÿæˆåˆ›ä½œå¤§çº²ï¼Œç›®æ ‡é•¿åº¦å»ºè®®{target_length}å­—ç¬¦"
        decisions = [
            f"ç ”ç©¶æ¦‚å¿µ: {novel_concept[:50]}{'...' if len(novel_concept) > 50 else ''}",
            f"ç”Ÿæˆå¤§çº²é•¿åº¦: {len(outline)} å­—ç¬¦",
            f"å»ºè®®ç›®æ ‡é•¿åº¦: {target_length} å­—ç¬¦"
        ]
        self.conversation_manager.add_meeting_minutes(
            stage="research_phase",
            participants=participants,
            summary=meeting_summary,
            decisions=decisions,
            turn_count=2  # mythologistå’Œwriterçš„äº¤äº’è½®æ¬¡
        )

        # 5. è®°å½•å¯¹è¯å†å²
        research_summary = {
            "concept": novel_concept,
            "outline": outline,
            "symbol_analysis": symbol_analysis,
            "target_length": target_length,
            "research_timestamp": __import__('datetime').datetime.now().isoformat()
        }
        self.conversation_manager.add_research_summary("initial_research", research_summary)

        # 5. è®¡ç®—ä¸­æ–‡æ±‰å­—æ•°é‡ï¼ˆåŒ…å«æ‰©å±•ä¸­æ–‡å­—ç¬¦ï¼‰
        import re
        # åŒ¹é…æ›´å¹¿èŒƒå›´çš„ä¸­æ–‡å­—ç¬¦ï¼ŒåŒ…æ‹¬åŸºæœ¬æ±‰å­—ã€æ‰©å±•Aã€Bã€Cã€DåŒºä»¥åŠä¸­æ–‡æ ‡ç‚¹ç¬¦å·
        chinese_pattern = r'[\u4e00-\u9fff\u3400-\u4dbf\U00020000-\U0002a6df\U0002a700-\U0002b73f\U0002b740-\U0002b81f\U0002b820-\U0002ceaf\uf900-\ufaff\u3000-\u303f\uff00-\uffef]'
        chinese_chars_count = len(re.findall(chinese_pattern, outline))
        print(f"\\nğŸ“Š ç ”ç©¶é˜¶æ®µå®Œæˆç»Ÿè®¡ï¼šæ¦‚è¿°å†…å®¹ {len(outline)} å­—ç¬¦ | {chinese_chars_count} ä¸­æ–‡å­—ç¬¦")

        # 6. è¿”å›ç ”ç©¶é˜¶æ®µæˆæœ
        research_data = {
            "concept": novel_concept,
            "outline": outline,
            "symbol_analysis": symbol_analysis,
            "target_length_suggestion": {
                "suggested": target_length,
                "confidence": (symbol_analysis.get("target_length", {}).get("confidence", 0.6)
                          if isinstance(symbol_analysis, dict) else 0.6)
            }
        }

        print("\\nâœ… ç ”ç©¶å’Œè§„åˆ’é˜¶æ®µå®Œæˆ")
        return research_data