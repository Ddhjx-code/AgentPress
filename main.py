# main.py
import asyncio
import os
from pathlib import Path
from dotenv import load_dotenv
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_core.models import ModelInfo, ModelFamily

from config import MODEL_CONFIG, PROMPTS_DIR, OUTPUT_DIR, CREATION_CONFIG
from utils import load_all_prompts, save_json, save_text
from agents_manager import AgentsManager
from conversation_manager import ConversationManager
from phases import NovelWritingPhases

async def main():
    """ä¸»ç¨‹åº"""
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    print("\n" + "="*60)
    print("ğŸš€ ç½‘ç»œå°è¯´AIåˆ›ä½œç³»ç»Ÿ")
    print("="*60)
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("QWEN_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: æœªè®¾ç½® QWEN_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    # åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯
    print("\nğŸ”Œ åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯...")
    model_client = OpenAIChatCompletionClient(
        model=MODEL_CONFIG["model"],
        api_key=api_key,
        base_url=MODEL_CONFIG["base_url"],
        model_info=ModelInfo(
            vision=MODEL_CONFIG["vision"],
            function_calling=MODEL_CONFIG["function_calling"],
            json_output=MODEL_CONFIG["json_output"],
            structured_output=False,
            family=ModelFamily.GPT_5
        )
    )
    print("âœ… æ¨¡å‹å®¢æˆ·ç«¯å°±ç»ª")
    
    # åŠ è½½æç¤ºè¯
    print("\nğŸ“– åŠ è½½æç¤ºè¯...")
    if not PROMPTS_DIR.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æç¤ºè¯ç›®å½• {PROMPTS_DIR}")
        return
    
    prompts = load_all_prompts(PROMPTS_DIR)
    if not prompts:
        print("âŒ é”™è¯¯: æ²¡æœ‰åŠ è½½åˆ°æç¤ºè¯æ–‡ä»¶")
        return
    
    print(f"âœ… åŠ è½½äº† {len(prompts)} ä¸ªæç¤ºè¯")
    
    # åˆå§‹åŒ–ç®¡ç†å™¨
    print("\nğŸ”§ åˆå§‹åŒ–ç®¡ç†å™¨...")
    agents_manager = AgentsManager(model_client)
    conversation_manager = ConversationManager()
    
    # åˆå§‹åŒ–Agent
    success = await agents_manager.initialize(prompts)
    if not success:
        print("âŒ é”™è¯¯: Agentåˆå§‹åŒ–å¤±è´¥")
        return
    
    # åˆå§‹åŒ–æµç¨‹ç®¡ç†å™¨
    phases = NovelWritingPhases(agents_manager, conversation_manager)
    
    # æ˜¾ç¤ºåˆ›ä½œé…ç½®
    print(f"\nâš™ï¸  åˆ›ä½œé…ç½®:")
    print(f"   åˆ›ä½œæ¨¡å¼: {'åˆ†ç« èŠ‚æ¨¡å¼' if CREATION_CONFIG['num_chapters'] > 1 else 'å•ç« æ¨¡å¼'}")
    print(f"   æ€»ç« æ•°: {CREATION_CONFIG['num_chapters']}")
    print(f"   æ¯ç« ç›®æ ‡å­—æ•°: {CREATION_CONFIG['target_length_per_chapter']} å­—")
    print(f"   æ€»ç›®æ ‡å­—æ•°: {CREATION_CONFIG['total_target_length']} å­—")
    
    # è·å–ç”¨æˆ·è¾“å…¥
    print("\n" + "="*60)
    print("ğŸ“ è¯·è¾“å…¥ä½ çš„å°è¯´åˆ›æ„")
    print("="*60)
    
    novel_concept = """
    åˆåŒ—äºŒç™¾é‡Œï¼Œæ›°å‘é¸ ä¹‹å±±ï¼Œå…¶ä¸Šå¤šæŸ˜æœ¨ã€‚æœ‰é¸Ÿç„‰ï¼Œå…¶çŠ¶å¦‚ä¹Œï¼Œæ–‡é¦–ã€ç™½å–™ã€èµ¤è¶³ï¼Œåæ›°ç²¾å«ï¼Œå…¶é¸£è‡ªè©¨ã€‚æ˜¯ç‚å¸ä¹‹å°‘å¥³ï¼Œåæ›°å¥³å¨ƒã€‚å¥³å¨ƒæ¸¸äºä¸œæµ·ï¼Œæººè€Œä¸è¿”ï¼Œæ•…ä¸ºç²¾å«ã€‚å¸¸è¡”è¥¿å±±ä¹‹æœ¨çŸ³ï¼Œä»¥å ™äºä¸œæµ·ã€‚
    """
    
    # å¯é€‰ï¼šä»ç”¨æˆ·è¾“å…¥è¯»å–
    # novel_concept = input("\nè¯·æè¿°ä½ çš„å°è¯´åˆ›æ„ï¼ˆæˆ–æŒ‰Enterä½¿ç”¨é»˜è®¤ç¤ºä¾‹ï¼‰:\n")
    # if not novel_concept.strip():
    #     novel_concept = default_concept
    
    print(f"\nğŸ“– ä½ çš„åˆ›æ„:")
    print(f"{novel_concept}")
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    try:
        final_output = await phases.run_full_pipeline(novel_concept)
        
        # ä¿å­˜ç»“æœ
        print("\n" + "="*60)
        print("ğŸ’¾ ä¿å­˜ç»“æœ")
        print("="*60)
        
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ•…äº‹æ–‡æœ¬
        story_file = OUTPUT_DIR / "novel_story.txt"
        save_text(final_output["final_story"], story_file)
        
        # ä¿å­˜å®Œæ•´æ•°æ®
        data_file = OUTPUT_DIR / "novel_data.json"
        save_json(final_output, data_file)
        
        # ä¿å­˜å¯¹è¯å†å²
        history_file = OUTPUT_DIR / "conversation_history.json"
        history_data = {
            "conversations": conversation_manager.conversation_history,
            "versions": conversation_manager.story_versions,
            "feedbacks": conversation_manager.feedback_records,
            "documentation": conversation_manager.documentation_records
        }
        save_json(history_data, history_file)
        
        # æ˜¾ç¤ºæ‘˜è¦
        print("\n" + "="*60)
        print("âœ… åˆ›ä½œå®Œæˆï¼")
        print("="*60)
        print(f"\nğŸ“Š åˆ›ä½œæ‘˜è¦:")
        print(f"  â€¢ æ•…äº‹å­—æ•°: {len(final_output['final_story'])} å­—")
        print(f"  â€¢ åˆ›å»ºç‰ˆæœ¬æ•°: {final_output['summary']['total_versions']}")
        print(f"  â€¢ è¯„å®¡è½®æ•°: {final_output['summary']['total_feedback_rounds']}")
        print(f"  â€¢ å¯¹è¯è½®æ•°: {final_output['summary']['total_conversations']}")
        print(f"  â€¢ åˆ›ä½œæ¨¡å¼: {'åˆ†ç« èŠ‚æ¨¡å¼' if CREATION_CONFIG['num_chapters'] > 1 else 'å•ç« æ¨¡å¼'}")
        
        if final_output['final_check']:
            print(f"  â€¢ å‘å¸ƒå°±ç»ª: {final_output['final_check'].get('ready_for_publication', False)}")
            print(f"  â€¢ æœ€ç»ˆè¯„åˆ†: {final_output['final_check'].get('final_score', 'N/A')}/100")
        
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  â€¢ æ•…äº‹æ–‡æœ¬: {story_file}")
        print(f"  â€¢ å®Œæ•´æ•°æ®: {data_file}")
        print(f"  â€¢ å¯¹è¯å†å²: {history_file}")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # å…³é—­æ¨¡å‹å®¢æˆ·ç«¯
        await model_client.close()
        print("\nğŸ‘‹ ç¨‹åºç»“æŸ")

if __name__ == "__main__":
    asyncio.run(main())
