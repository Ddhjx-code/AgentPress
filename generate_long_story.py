#!/usr/bin/env python3
"""
ç”Ÿæˆå¤§äº5000å­—çš„é•¿ç¯‡æ•…äº‹
"""
import asyncio
import sys
from pathlib import Path
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_path = Path(__file__).parent
sys.path.insert(0, str(project_path))

from config import CREATION_CONFIG
from src.novel_phases_manager import NovelWritingPhases
from core.agent_manager import AgentManager
from core.conversation_manager import ConversationManager
from src.documentation_manager import DocumentationManager
from utils import load_all_prompts
from autogen_ext.models.openai import OpenAIChatCompletionClient


async def generate_long_story():
    """ç”Ÿæˆä¸€ä¸ªå¤§äº5000å­—çš„é•¿ç¯‡æ•…äº‹"""
    # åŠ è½½æç¤ºè¯
    prompts_dir = Path("prompts")
    prompts = load_all_prompts(prompts_dir)

    # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦æç¤ºè¯
    if not prompts:
        print("âŒ æ— æ³•åŠ è½½æç¤ºè¯æ–‡ä»¶")
        return

    # æ›´æ–°åˆ›ä½œé…ç½®ä»¥æ”¯æŒæ›´é•¿çš„æ•…äº‹
    print("ğŸ“ æ›´æ–°é…ç½®ä»¥æ”¯æŒå¤§äº5000å­—çš„é•¿ç¯‡æ•…äº‹...")
    long_story_config = {
        'num_chapters': 1,
        'target_length_per_chapter': 6000,  # å¢åŠ æ¯ç« ç›®æ ‡åˆ°6000å­—
        'total_target_length': 6000        # æ€»ç›®æ ‡å­—æ•°è®¾ç½®ä¸º6000å­—
    }

    import os
    from dotenv import load_dotenv
    load_dotenv()  # åŠ è½½ç¯å¢ƒå˜é‡

    # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
    api_key = os.getenv("QWEN_API_KEY")
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°QWEN_API_KEYç¯å¢ƒå˜é‡")
        return

    # åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯ï¼Œä½¿ç”¨ModelInfo
    from autogen_core.models import ModelInfo, ModelFamily

    model_client = OpenAIChatCompletionClient(
        model="qwen3-max",
        api_key=api_key,
        base_url="https://apis.iflow.cn/v1",
        model_info=ModelInfo(
            vision=False,
            function_calling=True,
            json_output=True,
            structured_output=False,
            family=ModelFamily.GPT_5
        )
    )

    # åˆ›å»ºä»£ç†ç®¡ç†å™¨
    agent_manager = AgentManager(model_client)
    initialized = await agent_manager.initialize(prompts)

    if not initialized:
        print("âŒ ä»£ç†ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
        return

    # åˆ›å»ºå…¶ä»–å¿…è¦ç»„ä»¶
    conversation_manager = ConversationManager()
    documentation_manager = DocumentationManager()

    # åˆ›å»ºåˆ›ä½œæµç¨‹
    novel_phases = NovelWritingPhases(conversation_manager, documentation_manager)
    novel_phases.agents_manager = agent_manager

    # è¯»å–æµ‹è¯•æ¦‚å¿µ
    with open("test_concept.txt", 'r', encoding='utf-8') as f:
        concept = f.read()

    print(f"ğŸ“š ä½¿ç”¨æ¦‚å¿µ: {concept[:100]}...")

    print("ğŸ” å¼€å§‹ç¬¬ä¸€é˜¶æ®µï¼šç ”ç©¶å’Œè§„åˆ’...")
    research_data = await novel_phases.async_phase1_research_and_planning(concept)

    print("âœï¸ å¼€å§‹ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆå¤§äº5000å­—çš„é•¿ç¯‡æ•…äº‹...")
    long_story = await novel_phases.async_phase2_creation(research_data)

    # è®¡ç®—ä¸­æ–‡æ±‰å­—æ•°é‡ï¼Œè¿™æ›´ç¬¦åˆç”¨æˆ·å…³å¿ƒçš„æŒ‡æ ‡
    import re
    chinese_chars_count = len(re.findall(r'[\\u4e00-\\u9fff]', long_story))
    print(f"âœ… ç”Ÿæˆçš„é•¿ç¯‡æ•…äº‹é•¿åº¦: {len(long_story)} æ€»å­—ç¬¦ | {chinese_chars_count} ä¸­æ–‡æ±‰å­—")

    # ä¿å­˜ç”Ÿæˆçš„æ•…äº‹
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)

    story_file = output_dir / "long_story_6000_chars.txt"
    with open(story_file, 'w', encoding='utf-8') as f:
        f.write(long_story)

    print(f"ğŸ’¾ é•¿ç¯‡æ•…äº‹å·²ä¿å­˜: {story_file}")

    # ç”Ÿæˆè¿‡ç¨‹å¯è§†åŒ–æŠ¥å‘Š
    if hasattr(conversation_manager, 'print_meeting_minutes_summary'):
        print("\n" + "="*70)
        print("ğŸ“‹ é•¿ç¯‡æ•…äº‹ç”Ÿæˆè¿‡ç¨‹AIä»£ç†åä½œæ€»ç»“")
        print("="*70)
        conversation_manager.print_meeting_minutes_summary()

        # ä¿å­˜ä¼šè®®çºªè¦åˆ°æ–‡ä»¶
        conversation_manager.save_meeting_minutes_to_file()

        # ä½¿ç”¨ProcessVisualizerè¿›è¡Œé«˜çº§å¯è§†åŒ–åˆ†æ
        try:
            from src.process_visualizer import ProcessVisualizer
            visualizer = ProcessVisualizer()
            visualizer.visualize_meeting_minutes(conversation_manager, "file")
            visualizer.visualize_detailed_participants(conversation_manager, "file")
            visualizer.save_complete_process_log(conversation_manager)
        except Exception as e:
            print(f"âš ï¸  æ‰©å±•å¯è§†åŒ–å¤±è´¥: {e}")

    # åŒæ—¶ä¿å­˜å®Œæ•´çš„ä»£ç†å·¥ä½œæ—¥å¿—
    if hasattr(novel_phases, 'agent_work_log'):
        log_file = output_dir / "long_story_agent_log.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(novel_phases.agent_work_log, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“‹ ä»£ç†å·¥ä½œæ—¥å¿—å·²ä¿å­˜: {log_file}")

    return long_story


if __name__ == "__main__":
    try:
        result = asyncio.run(generate_long_story())
        if result and len(result) > 5000:
            print(f"\nğŸ‰ æˆåŠŸç”Ÿæˆå¤§äº5000å­—çš„é•¿ç¯‡æ•…äº‹! å®é™…é•¿åº¦: {len(result)} å­—ç¬¦")
        elif result:
            print(f"\nâš ï¸  ç”Ÿæˆçš„æ•…äº‹é•¿åº¦: {len(result)} å­—ç¬¦ï¼Œæ²¡æœ‰è¾¾åˆ°5000å­—ï¼Œå¯èƒ½éœ€è¦å¢åŠ è¿­ä»£æˆ–ä¸°å¯Œæƒ…èŠ‚å†…å®¹")
        else:
            print("\nâŒ ç”Ÿæˆå¤±è´¥")
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()